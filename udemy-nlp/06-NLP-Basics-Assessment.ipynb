{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('owlcreek.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ï»¿The Project Gutenberg EBook of An Occurrence at Owl Creek, by Ambrose Bierce\n",
       "\n",
       "This eBook is for the use of anyone anywhere at no cost and with\n",
       "almost no restrictions whatsoever.  "
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8740"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "len([sentence for sentence in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'This eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  '"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "sentences = [s for s in doc.sents]\n",
    "sentences[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This DET det this\neBook PROPN nsubj eBook\nis AUX ROOT be\nfor ADP prep for\nthe DET det the\nuse NOUN pobj use\nof ADP prep of\nanyone PRON pobj anyone\nanywhere ADV advmod anywhere\nat ADP prep at\nno DET det no\ncost NOUN pobj cost\nand CCONJ cc and\nwith ADP conj with\n\n SPACE  \n\nalmost ADV advmod almost\nno DET nummod no\nrestrictions NOUN pobj restriction\nwhatsoever ADV advmod whatsoever\n. PUNCT punct .\n  SPACE   \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sentences[1]:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A          DET        det        a         \nman        NOUN       nsubj      man       \nstood      VERB       ROOT       stand     \nupon       SCONJ      prep       upon      \na          DET        det        a         \nrailroad   NOUN       compound   railroad  \nbridge     NOUN       pobj       bridge    \nin         ADP        prep       in        \nnorthern   ADJ        amod       northern  \nAlabama    PROPN      pobj       Alabama   \n,          PUNCT      punct      ,         \nlooking    VERB       advcl      look      \ndown       ADV        prt        down      \n\n          SPACE                 \n         \ninto       ADP        prep       into      \nthe        DET        det        the       \nswift      ADJ        amod       swift     \nwater      NOUN       pobj       water     \ntwenty     NUM        nummod     twenty    \nfeet       NOUN       npadvmod   foot      \nbelow      ADV        advmod     below     \n.          PUNCT      punct      .         \n           SPACE                           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in sentences[15]:\n",
    "    print(f'{token.text:10} {token.pos_:10} {token.dep_:10} {token.lemma_:10}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "pattern = [ {\"lower\": \"swimming\"}, {\"IS_SPACE\" : True, 'OP':'*'}, {\"lower\": 'vigorously'}]\n",
    "\n",
    "matcher.add(\"Swimming\", None, pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(12881893835109366681, 1396, 1399), (12881893835109366681, 3731, 3734)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " By diving I could evade the bullets and, swimming\n",
       "vigorously, reach the bank, take to"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "doc[found_matches[0][1]-10:found_matches[0][1]+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "saw all this over his shoulder; he was now swimming\n",
       "vigorously with the current.  His brain"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "doc[found_matches[1][1]-10:found_matches[1][1]+10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "By diving I could evade the bullets and, swimming\nvigorously, reach the bank, take to the woods and get away home.  \nThe hunted man saw all this over his shoulder; he was now swimming\nvigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    if doc[found_matches[0][1]:found_matches[0][2]].text in sent.text:\n",
    "       print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}